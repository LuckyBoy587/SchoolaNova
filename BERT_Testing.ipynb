{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuckyBoy587/SchoolaNova/blob/main/BERT_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESaxZ80KkEB2",
        "outputId": "6c4bae7f-6da9-4fce-f30d-c88befac78db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "tensor([[0.5394, 0.3054, 0.3463]])\n",
            "Question: How do plants cook themselves?\n",
            "Best Match: Photosynthesis is the process by which green plants make food using sunlight, carbon dioxide, and water.\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install faiss-cpu\n",
        "!pip install nltk\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# 1. Load embedding model (pretrained on similarity tasks)\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "\n",
        "# 2. Sample NCERT-like paragraphs\n",
        "docs = [\n",
        "    \"Photosynthesis is the process by which green plants make food using sunlight, carbon dioxide, and water.\",\n",
        "    \"Respiration is the process by which living organisms release energy from food molecules.\",\n",
        "    \"Chlorophyll is a green pigment in plants that helps capture sunlight for photosynthesis.\"\n",
        "]\n",
        "\n",
        "# 3. Encode the paragraphs\n",
        "doc_embeddings = model.encode(docs, convert_to_tensor=True)\n",
        "\n",
        "# 4. Encode a sample question\n",
        "question = \"How do plants cook themselves?\"\n",
        "query_embedding = model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "# 5. Compute similarity\n",
        "cosine_scores = util.cos_sim(query_embedding, doc_embeddings)\n",
        "print(cosine_scores)\n",
        "\n",
        "# 6. Retrieve best paragraph\n",
        "best_idx = cosine_scores.argmax()\n",
        "print(\"Question:\", question)\n",
        "print(\"Best Match:\", docs[best_idx])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AotDV3TWJv_X"
      },
      "outputs": [],
      "source": [
        "import pdfplumber, re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Aggressively clean NCERT/School-book style PDF text with OCR noise.\"\"\"\n",
        "    # Normalize spaces/newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove OCR garbled \"CChhaapptteerr\" like strings\n",
        "    text = re.sub(r'C+H*A+P+T+E+R+.*?\\d+', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove lines with .indd and timestamps (OCR file tags)\n",
        "    text = re.sub(r'\\.?i+n+d+d+\\s*\\d+.*?(AM|PM)?', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove publisher footer lines\n",
        "    text = re.sub(r'Curiosity.*?(Grade|Gr\\.a\\.d\\.e)', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove \"Chapter ...\" repeated headers (even broken ones)\n",
        "    text = re.sub(r'Chapter\\s+The.*?Solutions', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove random numbers/dates like //2288//22002255 ::0066::3366\n",
        "    text = re.sub(r'[/:\\d]+', '', text)\n",
        "\n",
        "    # Collapse multiple punctuation (.... → . , ??? → ? , !!! → !)\n",
        "    text = re.sub(r'([.?!])\\1+', r'\\1', text)\n",
        "\n",
        "    # Remove bullets/list markers\n",
        "    text = re.sub(r'[\\\\•\\·\\●\\-\\–\\—\\»\\\"z]', '', text)\n",
        "\n",
        "    # Normalize ligatures\n",
        "    text = text.replace('ﬁ', 'fi').replace('ﬂ', 'fl')\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def pdf_to_sentences(pdf_path: str):\n",
        "    \"\"\"Extract sentences from PDF and clean them.\"\"\"\n",
        "    all_sentences = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            raw_text = page.extract_text()\n",
        "            if not raw_text:\n",
        "                continue\n",
        "            # Clean and split into sentences\n",
        "            cleaned = clean_text(raw_text)\n",
        "            sentences = sent_tokenize(cleaned)\n",
        "            for s in sentences:\n",
        "                s = s.strip()\n",
        "                if len(s.split()) > 5:  # skip very tiny fragments\n",
        "                    all_sentences.append(s)\n",
        "    return all_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abfe2459",
        "outputId": "5ca631e3-2793-4de6-efbc-54c149b2b2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ch9_sentences = pdf_to_sentences(\"/content/drive/MyDrive/ColabContent/ch9.pdf\")"
      ],
      "metadata": {
        "id": "pcVJEr2fzQSI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "ch9_embeddings = model.encode(ch9_sentences, convert_to_tensor=False) # Convert to numpy array for FAISS\n",
        "\n",
        "# create a FAISS index\n",
        "d = ch9_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(ch9_embeddings)\n",
        "\n",
        "print(f\"Created FAISS index with {index.ntotal} vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9MWK8v3yD7q",
        "outputId": "704b765f-5d9f-4280-f3f9-fbaa237a2c27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created FAISS index with 323 vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"What is a solute and a solvent?\"\n",
        "my_question_embd = model.encode(my_question, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "wrUFwBRQyOvp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Encode the question and convert to numpy\n",
        "my_question_embd_np = model.encode([my_question], convert_to_tensor=False)\n",
        "\n",
        "# Search the FAISS index\n",
        "top_k = 5\n",
        "distances, indices = index.search(my_question_embd_np, top_k)\n",
        "\n",
        "print(\"Question:\", my_question)\n",
        "print(f\"Top {top_k} Matches:\")\n",
        "for i in range(top_k):\n",
        "    print(f\"- {ch9_sentences[indices[0][i]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtIgUexGzDi5",
        "outputId": "aac1205e-9d1c-43ec-e8e2-12c2c0a505fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is a solute and a solvent?\n",
            "Top 5 Matches:\n",
            "- What Are Solute, Solvent, and Solution?\n",
            "- In a solution formed by mixing two liquids, the component present in less quantity is known as solute and the other component is called solvent.\n",
            "- Solvent Solute + Solvent Solution When a solution is formed by mixing two liquids, it is not always clear which substance is dissolving the other.\n",
            "- Magnified schematic picture of a cases, the substance present in smaller solute evenly distributed in a solvent amount is called the solute, while the one in larger amount is called the solvent.\n",
            "- Whenever a solid is mixed with a liquid to form a solution, the solid component is called the solute, and the liquid component is called the solvent.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18ehIMpnpFDHq0eBZdybKMOcyl0NqOgyA",
      "authorship_tag": "ABX9TyMX3s5FNqtcPOFe4+rGRVtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}