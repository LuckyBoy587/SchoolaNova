{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuckyBoy587/SchoolaNova/blob/main/BERT_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESaxZ80KkEB2",
        "outputId": "cb638581-9602-431e-93a4-5080ac535c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install faiss-cpu\n",
        "!pip install nltk\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# 1. Load embedding model (pretrained on similarity tasks)\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "AotDV3TWJv_X"
      },
      "outputs": [],
      "source": [
        "import pdfplumber, re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Aggressively clean NCERT/School-book style PDF text with OCR noise.\"\"\"\n",
        "    # Normalize spaces/newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove OCR garbled \"CChhaapptteerr\" like strings\n",
        "    text = re.sub(r'C+H*A+P+T+E+R+.*?\\d+', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove lines with .indd and timestamps (OCR file tags)\n",
        "    text = re.sub(r'\\.?i+n+d+d+\\s*\\d+.*?(AM|PM)?', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove publisher footer lines\n",
        "    text = re.sub(r'Curiosity.*?(Grade|Gr\\.a\\.d\\.e)', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove \"Chapter ...\" repeated headers (even broken ones)\n",
        "    text = re.sub(r'Chapter\\s+The.*?Solutions', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Define the core tokens once\n",
        "    fig_core = r'(?:Fig\\.?|Figure)\\s*:?\\s*\\d+(?:[.\\-\\u2013]\\d+)*(?:[A-Za-z])?(?:\\([A-Za-z]\\))?'\n",
        "    tab_core = r'(?:Tab\\.?|Table)\\s*:?\\s*\\d+(?:[.\\-\\u2013]\\d+)*(?:[A-Za-z])?(?:\\([A-Za-z]\\))?'\n",
        "\n",
        "    # 1) Remove unbracketed inline refs like \"Fig. 9.10a\" or \"Table 4.1,\"\n",
        "    text = re.sub(rf'\\b(?:{fig_core}|{tab_core})(?:\\s*[:.,;])?', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # 2) Remove bracketed inline refs like \"(Fig. 9.10a)\" or \"(Figure 3(b))\"\n",
        "    text = re.sub(rf'\\(\\s*(?:{fig_core}|{tab_core})\\s*\\)(?:\\s*[:.,;])?', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # 3) Remove full caption lines starting with these tokens (with or without brackets)\n",
        "    text = re.sub(rf'(?mi)^\\s*(?:\\(\\s*)?(?:{fig_core}|{tab_core})(?:\\s*\\))?\\s+.*$', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "    # 1) Dates like 12/10/2021 or 12-10-21\n",
        "    text = re.sub(r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b', '', text)\n",
        "\n",
        "    # 2) Time like 12:30 or 12:30:45\n",
        "    text = re.sub(r'\\b\\d{1,2}:\\d{2}(?::\\d{2})?\\b', '', text)\n",
        "\n",
        "    # 3) Weird ::0066::3366 blobs (keep the colons, drop number blobs between them)\n",
        "    text = re.sub(r'::\\d+::', '::', text)\n",
        "\n",
        "    # 4) Standalone page-like counters with lots of slashes (//2288// style)\n",
        "    text = re.sub(r'/{2,}\\d+/{2,}', ' ', text)\n",
        "\n",
        "    # 5) Hyphenated index codes like 2020-001-33 at line edges (optional, be careful)\n",
        "    text = re.sub(r'\\b\\d{4}-\\d{1,3}-\\d{1,3}\\b', '', text)\n",
        "\n",
        "\n",
        "    # Collapse multiple punctuation (.... → . , ??? → ? , !!! → !)\n",
        "    text = re.sub(r'([.?!])\\1+', r'\\1', text)\n",
        "\n",
        "    text = re.sub(r\"\\(\\)\", \"\", text)\n",
        "\n",
        "    # Remove bullets/list markers\n",
        "    text = re.sub(r'[\\\\•\\·\\●\\-\\–\\—\\»\\\"z]', '', text)\n",
        "\n",
        "    # Normalize ligatures\n",
        "    text = text.replace('ﬁ', 'fi').replace('ﬂ', 'fl')\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def pdf_to_sentences(pdf_path: str):\n",
        "    \"\"\"Extract sentences from PDF and clean them.\"\"\"\n",
        "    all_sentences = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            raw_text = page.extract_text()\n",
        "            if not raw_text:\n",
        "                continue\n",
        "            # Clean and split into sentences\n",
        "            cleaned = clean_text(raw_text)\n",
        "            sentences = sent_tokenize(cleaned)\n",
        "            for s in sentences:\n",
        "                s = s.strip()\n",
        "                if len(s.split()) > 5:  # skip very tiny fragments\n",
        "                    all_sentences.append(s)\n",
        "    return all_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abfe2459",
        "outputId": "1c42482f-8922-4384-f764-a81b0a7eb699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ch9_sentences = pdf_to_sentences(\"/content/drive/MyDrive/ColabContent/ch9.pdf\")"
      ],
      "metadata": {
        "id": "pcVJEr2fzQSI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "ch9_embeddings = model.encode(ch9_sentences, convert_to_tensor=False) # Convert to numpy array for FAISS\n",
        "\n",
        "# create a FAISS index\n",
        "d = ch9_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(ch9_embeddings)\n",
        "\n",
        "print(f\"Created FAISS index with {index.ntotal} vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9MWK8v3yD7q",
        "outputId": "176fb7c5-573c-45dc-ed93-1dbdc57165a5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created FAISS index with 293 vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"If you have a block of iron and a piece of wood that are the same size, which one is denser? Why?\"\n",
        "my_question_embd = model.encode(my_question, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "wrUFwBRQyOvp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Encode the question and convert to numpy\n",
        "my_question_embd_np = model.encode([my_question], convert_to_tensor=False)\n",
        "\n",
        "# Search the FAISS index\n",
        "top_k = 3\n",
        "distances, indices = index.search(my_question_embd_np, top_k)\n",
        "\n",
        "print(\"Question:\", my_question)\n",
        "print(f\"Top {top_k} Matches:\")\n",
        "for i in range(top_k):\n",
        "    print(f\"- {ch9_sentences[indices[0][i]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtIgUexGzDi5",
        "outputId": "9120a554-84cd-4f7f-d722-1089992ad4af"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: If you have a block of iron and a piece of wood that are the same size, which one is denser? Why?\n",
            "Top 3 Matches:\n",
            "- A block of iron has a mass of 600 g and a density of 7.9 g/cm³.\n",
            "- When we say that iron while others sink in water is heavier than wood, we are referring to a special property known as density, which describes the heaviness of an object.\n",
            "- A wooden stick and an iron rod may be of the same sie,  Some objects float yet the iron rod feels much heavier.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18ehIMpnpFDHq0eBZdybKMOcyl0NqOgyA",
      "authorship_tag": "ABX9TyPTMzwPf3Prz/nBggt0yVTT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}